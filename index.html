<!doctype html>
<html>

<head>
<title>Kun Yuan</title>
<link rel="icon" type="image/webp" href="imgs/icon.webp">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Kun Yuan, Kuaishou Technology, Artificial Intelligence, Computer Vision, 袁坤, 快手科技"> 
<meta name="description" content="Kun Yuan's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-137722442-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- Show more content -->
<script type="text/javascript">
    function toggle_vis(id) {
        // var e = document.getElementById(id);
        var e = document.getElementsByClassName(id);
        var showText = document.getElementById("showText");
        for (var i = 0; i < e.length; i++) {
            if (e[i].style.display == "none") {
                e[i].style.display = "inline";
                showText.innerHTML = "[Show less]";
            } else {
                e[i].style.display = "none";
                showText.innerHTML = "[Show more]";
            }
        }
    }

    function toggle_research_vis(target, tabElement) {
        var is_current_summary = 0;

        var e = document.getElementsByClassName("research_summary");
        for (var i = 0; i < e.length; i++) {
            if (e[i].id == target) {
                if (e[i].style.display == "inline") {
                    is_current_summary = 1;
                } else {
                    e[i].style.display = "inline";
                }
            } else {
                e[i].style.display = "none";
            }
        }

        var e = document.getElementsByClassName("progress_button");
        for (var i = 0; i < e.length; i++) {
            if (e[i].id == target + "_button") {
                if (is_current_summary == 0) {
                    e[i].style.display = "inline";
                }
            } else {
                e[i].style.display = "none";
            }
        }

        var e = document.getElementsByClassName("goal_tabs");
        for (var i = 0; i < e.length; i++) {
            if (e[i].id != target + "_goal_tabs") {
                e[i].style.display = "none";
            }
        }

        var e = document.getElementsByClassName("highlight_research_tab");
        for (var i = 0; i < e.length; i++) {
            e[i].className = "research_tab";
        }
        tabElement.className = "highlight_research_tab"
    }

    function toggle_goal_vis(id, goal_tabs_id, goal) {
        var e = document.getElementById(id);
        e.style.display = "none";
        var goal_tabs = document.getElementById(goal_tabs_id);
        goal_tabs.style.display = "inline";

        var goal_tab = document.getElementById(goal + "_tab");
        toggle_goal_progress_vis(goal_tab);
        // add_goal_progress_div(goal);
    }

    function toggle_goal_progress_vis(tabElement) {
        var target = tabElement.id;
        target = target.substring(0, target.length - 4);

        var e = document.getElementsByClassName("goal_progress");
        for (var i = 0; i < e.length; i++) {
            if (e[i].id == target) {
                e[i].style.display = "inline";
            } else {
                e[i].style.display = "none";
            }
        }

        var e = document.getElementsByClassName("highlight_goal_tab");
        for (var i = 0; i < e.length; i++) {
            e[i].className = "goal_tab";
        }
        tabElement.className = "highlight_goal_tab"

        add_goal_progress_div(target);
    }

    function add_goal_progress_div(goal) {
        var e = document.getElementById(goal);
        if (e && e.children.length == 0) {
            var children = Array.from(document.getElementsByClassName(goal));
            for (var i = 0; i < children.length; i++) {
                var cloned_div = children[i].cloneNode(true);
                cloned_div.className = "publication_container";
                e.appendChild(cloned_div);
            }
        }
    }
</script>

</head>


<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Kun Yuan (袁坤)<h1>
				</div>

                <h3 class="title">R&D Engineer in Artificial Intelligence and Computer Vision</h3> </h1>

				<p>
                    
                    Video Technology Group, Kuaishou Technology</br></br>

		        <b>Research Interests: </b> Visual Content Generation, Video Quality Assessment, Video Enhancement and Restoration, AI Infrastructure</br>
                    Email: <a href="mailto:yuankunbupt@gmail.com">yuankunbupt dot gmail dot com </a></br>
					</br>
                    [<a href="https://scholar.google.com/citations?user=fCeZ32EAAAAJ&hl=zh-CN">Google Scholar</a>] </br> 
				</p>

			</td>
			<td width="25%">
				<img src="photo/KunYuan.jpg" width="70%"/>
			</td>
		<tr>
	</tbody>
</table>

<h2>Short Bio</h2> 

<div style="display: flex; margin-bottom: -10px">
    <p>
	    I am currently a senior Research & Development Engineer at <a href="https://www.kuaishou.com/en/">Kuaishou Technology</a> since 2021. 
        Formerly I worked in <a href="https://www.sensetime.com/en">SenseTime Research</a> in 2018 as a Computer Vision and Machine Learning Researcher. 
        Formerly I was with the National Laboratory of Pattern Recognition (NLPR), <a href="https://www.sensetime.com/en">Institute of Automation</a>, Chinese Academy of Science since 2015. 
    </br></br>
        My research interests are in visual content generation, video quality assessment, video enhancement and restoration, neural architecture design and AI infrastructure.
		</br>
		<!--<b>I'd like to connect with anyone who's passionate about research. Excited for some great intellectual discussions!</b>-->
    </p>
</div>

<h2>News</h2>

<ul>
	<li>
        <div class="marker">[2024-07] One paper accepted by ECCV 2024.</div>
    </li>
    <li>
        <div class="marker">[2024-03] Two paper accepted by CVPR 2024.</div>
    </li>
    <li>
        <div class="marker">[2023-10] Two paper accepted by ACM MM 2023.</div>
    </li>
    <li>
        <div class="marker">[2023-03] One paper accepted by CVPR 2023.</div>
    </li>
    <li>
        <div class="marker">[2022-03] One paper accepted by CVPR 2022.</div>
    </li>
    <li>
        <div class="marker">[2021-02] One paper accepted by ICLR 2021.</div>
    </li>
    <li>
        <div class="marker">[2021-02] Two paper accepted by ICCV 2021.</div>
    </li>
    <li>
        <div class="marker">[2020-08] One paper accepted by ECCV 2020.</div>
    </li>
    <li>
        <div class="marker">[2018-07] One paper accepted by IJCAI 2018.</div>
    </li>

</ul>

<div class="show_button">
    <a href="javascript:toggle_vis('news')" id="showText">[Show more]</a>
</div>

<h2>
    Publications
    <span style="font-size: 50%;">(* denotes equal contribution, # denotes corresponding author)</span>
</h2>

<div class="newline_bg">
    <h3>2024</h3>
</div>

<div class="publication_container scene_generation">
    <div class="publication_image">
        <img src="paper_teaser/ECCV2024/xpsr.png">
    </div>
    <div class="publication_title">
        XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution</br>
        Yunpeng Qu*, <b>Kun Yuan*</b>, Kai Zhao, Qizhi Xie, Jinhua Hao, Ming Sun, Chao Zhou</br>
	    European Conference on Computer Vision (ECCV), 2024.</br>
        [<a href="https://arxiv.org/abs/2403.05049">Paper</a>][<a href="https://github.com/qyp2000/XPSR">Project Page</a>]
    </div>
</div>

<div class="publication_container scene_generation">
    <div class="publication_image">
        <img src="paper_teaser/CVPR2024/kvq.png">
    </div>
    <div class="publication_title">
        KVQ: Kwai Video Quality Assessment for Short-form Videos</br>
        Yiting Lu*, Xin Li*, Yajing Pei*, <b>Kun Yuan#</b>, Qizhi Xie, Yunpeng Qu, Ming Sun, Chao Zhou, Zhibo Chen#</br>
	    IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024.</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Lu_KVQ_Kwai_Video_Quality_Assessment_for_Short-form_Videos_CVPR_2024_paper.pdf">Paper</a>]
        [<a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Lu_KVQ_Kwai_Video_CVPR_2024_supplemental.pdf">Supp</a>]
        [<a href="https://lixinustc. github. io/projects/KVQ">Project Page</a>]
    </div>
</div>

<div class="publication_container scene_generation">
    <div class="publication_image">
        <img src="paper_teaser/CVPR2024/ptmvqa.png">
    </div>
    <div class="publication_title">
        PTM-VQA: Efficient Video Quality Assessment Leveraging Diverse PreTrained Models from the Wild</br>
        <b>Kun Yuan*</b>, Hongbo Liu*, Mading Li*, Muyi Sun, Ming Sun, Jiachao Gong, Jinhua Hao, Chao Zhou, Yansong Tang</br>
	    IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024.</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yuan_PTM-VQA_Efficient_Video_Quality_Assessment_Leveraging_Diverse_PreTrained_Models_from_CVPR_2024_paper.pdf">Paper</a>]
    </div>
</div>

<div class="newline_bg">
    <h3>2023</h3>
</div>

<div class="publication_container scene_generation">
    <div class="publication_image">
        <img src="paper_teaser/ACMMM2023/vqt.png">
    </div>
    <div class="publication_title">
        Capturing Co-existing Distortions in User-Generated Content for No-reference Video Quality Assessment</br>
        <b>Kun Yuan*</b>, Zishang Kong*, Chuanchuan Zheng, Ming Sun, Xing Wen</br>
	    ACM International Conference on Multimedia (ACM MM), 2023.</br>
        [<a href="https://arxiv.org/pdf/2307.16813">Paper</a>]
    </div>
</div>

<div class="publication_container scene_generation">
    <div class="publication_image">
        <img src="paper_teaser/ACMMM2023/adadqa.png">
    </div>
    <div class="publication_title">
        Ada-DQA: Adaptive Diverse Quality-aware Feature Acquisition for Video Quality Assessment</br>
        Hongbo Liu*, Mingda Wu*, <b>Kun Yuan*</b>, Ming Sun, Yansong Tang, Chuanchuan Zheng, Xing Wen, Xiu Li</br>
	    ACM International Conference on Multimedia (ACM MM), 2023.</br>
        [<a href="https://dl.acm.org/doi/pdf/10.1145/3581783.3611795">Paper</a>]
    </div>
</div>

<div class="publication_container scene_generation">
    <div class="publication_image">
        <img src="paper_teaser/CVPR2023/qpt.png">
    </div>
    <div class="publication_title">
        Quality-aware Pre-trained Models for Blind Image Quality Assessment</br>
        Kai Zhao*, <b>Kun Yuan*</b>, Ming Sun, Mading Li, Xing Wen</br>
	    IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</br>
        [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Quality-Aware_Pre-Trained_Models_for_Blind_Image_Quality_Assessment_CVPR_2023_paper.pdf">Paper</a>]
    </div>
</div>


</div>
</body>
</html>
